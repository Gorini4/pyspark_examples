{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9abb3dfa-dcbb-489b-9250-8a003917314d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import IntegerType, StringType\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdba5aba-f394-4166-8263-8708c18b1b2e",
   "metadata": {},
   "source": [
    "# Apache Arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4bac197-5e22-46de-a95b-a175bb206c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "import pyarrow\n",
    "\n",
    "df = pandas.DataFrame({'one': [-1, np.nan, 2.5],\n",
    "                   'two': ['foo', 'bar', 'baz'],\n",
    "                   'three': [True, False, True]},\n",
    "                   index=list('abc'))\n",
    "\n",
    "\n",
    "table = pyarrow.Table.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3b5dfb-cfb0-4c4c-b328-5dd8b6fe9f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarrow import parquet\n",
    "\n",
    "parquet.write_table(table, 'example.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f2df7-c720-403e-9641-2fa80545a3e1",
   "metadata": {},
   "source": [
    "# Обычные UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ccd4be9-d59e-40e2-8457-c3d1dd16545b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+\n",
      "| id|    name|age|\n",
      "+---+--------+---+\n",
      "|  1|John Doe| 21|\n",
      "+---+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame([(1, \"John Doe\", 21)], (\"id\", \"name\", \"age\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3df116a-1f9a-422e-aeb2-b01288d46cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|string_length|string_length2|\n",
      "+-------------+--------------+\n",
      "|            8|             8|\n",
      "+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "string_length = udf(lambda s: len(s))\n",
    "\n",
    "@udf\n",
    "def string_length2(s):\n",
    "    return len(s)\n",
    "\n",
    "df.select(string_length(col('name')).alias('string_length'), string_length2(col('name')).alias('string_length2')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9de630-c5b9-4282-be21-a2f7164766f7",
   "metadata": {},
   "source": [
    "# Pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e40a49cb-912b-4a97-9294-86dca732287a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/functions.py:399: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(StringType(), PandasUDFType.SCALAR)\n",
    "def to_upper(s):\n",
    "    return s.str.upper()\n",
    "\n",
    "@pandas_udf(\"integer\", PandasUDFType.SCALAR)\n",
    "def add_one(x):\n",
    "    return x + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "096f50c8-ef00-45de-b7fa-fd7bdb70c4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------+\n",
      "|to_upper(name)|add_one(age)|\n",
      "+--------------+------------+\n",
      "|      JOHN DOE|          22|\n",
      "+--------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(to_upper(\"name\"), add_one(\"age\")) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d99f71ad-1721-4311-9d4f-44f539697839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(\n",
    "    [(1, 1.0), (1, 2.0), (2, 3.0), (2, 5.0), (2, 10.0)],\n",
    "    (\"id\", \"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99649ea8-c338-4652-bcf5-61b3dd4dde28",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"id long, value double\", PandasUDFType.GROUPED_MAP)\n",
    "def normalize(pdf):\n",
    "    v = pdf.value\n",
    "    return pdf.assign(value=(v - v.mean()) / v.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7a781a9-56f7-4e3a-ad8f-c3f276fbc5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/pandas/group_ops.py:103: UserWarning: It is preferred to use 'applyInPandas' over this API. This API will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+\n",
      "| id|              value|\n",
      "+---+-------------------+\n",
      "|  1|-0.7071067811865475|\n",
      "|  1| 0.7071067811865475|\n",
      "|  2|-0.8320502943378437|\n",
      "|  2|-0.2773500981126146|\n",
      "|  2| 1.1094003924504583|\n",
      "+---+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby(\"id\").apply(normalize).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fb453b7-b74e-4b10-bf97-8adaa9760a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pandas_udf(\"double\", PandasUDFType.GROUPED_AGG)\n",
    "def mean_udf(v):\n",
    "    return v.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "818a1396-b7cd-40f4-bbaa-c7ab79789c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+\n",
      "| id|value|mean_v|\n",
      "+---+-----+------+\n",
      "|  1|  1.0|   1.5|\n",
      "|  1|  2.0|   1.5|\n",
      "|  2|  3.0|   6.0|\n",
      "|  2|  5.0|   6.0|\n",
      "|  2| 10.0|   6.0|\n",
      "+---+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "\n",
    "w = Window \\\n",
    "    .partitionBy('id') \\\n",
    "    .rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "df.withColumn('mean_v', mean_udf(df['value']).over(w)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d61023-8ac1-4d53-b5a1-871450b3b690",
   "metadata": {},
   "source": [
    "# Spark 3 UDF (Type Hints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "245c41e5-2868-40a8-b298-9ad5a3f16016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import pandas_udf, PandasUDFType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d229195d-fb7f-459d-ba8e-f5f679f5f5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|pandas_plus_one(id)|\n",
      "+-------------------+\n",
      "|                  1|\n",
      "|                  2|\n",
      "|                  3|\n",
      "|                  4|\n",
      "|                  5|\n",
      "|                  6|\n",
      "|                  7|\n",
      "|                  8|\n",
      "|                  9|\n",
      "|                 10|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf('long', PandasUDFType.SCALAR)\n",
    "def pandas_plus_one(v):\n",
    "    return v + 1\n",
    "\n",
    "spark.range(10).select(pandas_plus_one(\"id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a98c35a2-cb7d-487d-bf8c-5aff20f03d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|pandas_plus_one(id)|\n",
      "+-------------------+\n",
      "|                  1|\n",
      "|                  2|\n",
      "|                  3|\n",
      "|                  4|\n",
      "|                  5|\n",
      "|                  6|\n",
      "|                  7|\n",
      "|                  8|\n",
      "|                  9|\n",
      "|                 10|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf('long')\n",
    "def pandas_plus_one(s: pd.Series) -> pd.Series:\n",
    "    return s + 1\n",
    "\n",
    "spark.range(10).select(pandas_plus_one(\"id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c418c0aa-4567-4f26-a121-3d8850bcd6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|multiply_two(id, id)|\n",
      "+--------------------+\n",
      "|                   0|\n",
      "|                   1|\n",
      "|                   4|\n",
      "|                   9|\n",
      "|                  16|\n",
      "|                  25|\n",
      "|                  36|\n",
      "|                  49|\n",
      "|                  64|\n",
      "|                  81|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf('long', PandasUDFType.SCALAR_ITER) # New in 3.0\n",
    "def multiply_two(iterator):\n",
    "    return (a * b for a, b in iterator)\n",
    "\n",
    "spark.range(10).select(multiply_two(\"id\", \"id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b1d48cf-46a0-4fdb-85e7-5ccc19f4e9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|multiply_two(id, id)|\n",
      "+--------------------+\n",
      "|                   0|\n",
      "|                   1|\n",
      "|                   4|\n",
      "|                   9|\n",
      "|                  16|\n",
      "|                  25|\n",
      "|                  36|\n",
      "|                  49|\n",
      "|                  64|\n",
      "|                  81|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from typing import Iterator, Tuple       \n",
    "\n",
    "@pandas_udf(\"long\")\n",
    "def multiply_two(\n",
    "        iterator: Iterator[Tuple[pd.Series, pd.Series]]) -> Iterator[pd.Series]:\n",
    "    return (a * b for a, b in iterator)\n",
    "\n",
    "spark.range(10).select(multiply_two(\"id\", \"id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1682c638-f3e7-4698-aa3f-ffdd4e444d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+---+\n",
      "|time| id| v1| v2|\n",
      "+----+---+---+---+\n",
      "|1201|  1|1.0|  x|\n",
      "|1202|  1|3.0|  x|\n",
      "|1201|  2|2.0|  y|\n",
      "|1202|  2|4.0|  y|\n",
      "+----+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1 = spark.createDataFrame(\n",
    "    [(1201, 1, 1.0), (1201, 2, 2.0), (1202, 1, 3.0), (1202, 2, 4.0)],\n",
    "    (\"time\", \"id\", \"v1\"))\n",
    "df2 = spark.createDataFrame(\n",
    "    [(1201, 1, \"x\"), (1201, 2, \"y\")], (\"time\", \"id\", \"v2\"))\n",
    "\n",
    "def asof_join(left: pd.DataFrame, right: pd.DataFrame) -> pd.DataFrame:\n",
    "    return pd.merge_asof(left, right, on=\"time\", by=\"id\")\n",
    "\n",
    "df1.groupby(\"id\").cogroup(\n",
    "    df2.groupby(\"id\")\n",
    ").applyInPandas(asof_join, \"time int, id int, v1 double, v2 string\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716e7455-e6ce-4841-bd37-8398f4eaa4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
